{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm, binom, spearmanr\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax.lax import cond\n",
    "import scipy.optimize as opt\n",
    "from jax.scipy.special import expit, logit, xlogy\n",
    "from scipy.special import comb\n",
    "import os\n",
    "from ipywidgets import interact, FloatSlider, Dropdown\n",
    "import ipywidgets as widgets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "cpu_device = jax.devices(\"cpu\")\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "fontx=12\n",
    "fonty=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def compute_t_2D(ρ, α, β):\n",
    "    FDR = (1 - 2 * α + 2 * ρ) / (2 * (1 - 2 * α))  # eq 3a\n",
    "    return 1 - FDR\n",
    "\n",
    "@jax.jit\n",
    "def compute_t_3D(ρ, α, β):\n",
    "    Δ = 4 * α * α - 4 * α + 4 * β * β + 1 + 8 * β * ρ\n",
    "    FDR = (2 * α + 2 * β - 1 + jnp.sqrt(Δ)) / (4 * β)  # eq 3\n",
    "    return 1 - FDR\n",
    "\n",
    "@jax.jit   \n",
    "def compute_t(ρ, α, β):\n",
    "    \"\"\"Generate t - the true incidence of left-handedness\n",
    "\n",
    "    From Laland at al., (1995):\n",
    "    F_DR is the final equilibrium frequency of right-handers with allele D fixed\n",
    "    We need F_DL = 1 - F_DR\n",
    "    \"\"\"\n",
    "    return cond(jnp.isclose(β, 0), compute_t_2D, compute_t_3D, ρ, α, β)    \n",
    "\n",
    "\n",
    "@jax.jit   \n",
    "def validate(θ):\n",
    "    if len(θ) == 3: # when estimating all three parameters (ρ, α, β)\n",
    "        ρ, α, β = θ\n",
    "    elif len(θ) == 2:   # when estimating ρ, α - fix β to zero\n",
    "        ρ, α = θ\n",
    "        β = 0\n",
    "    else:\n",
    "        raise ValueError(\"Length of θ is {}\".format(len(θ)))\n",
    "\n",
    "    unvalid = (ρ < 0) | (ρ > 1) | (α < 0) | (α > 1) | (β < 0) | (β > 1) | (ρ + α >= 0.5) | (ρ - α > 0.5) | (ρ + β > 0.5) # model constrain of parameters\n",
    "    return jnp.logical_not(unvalid)\n",
    "##################################################\n",
    "### MATRICES\n",
    "\n",
    "\n",
    "@jax.jit   \n",
    "def compute_T(ρ, α, β):\n",
    "    \"\"\"Generate T - column DD in Table 1\n",
    "\n",
    "    From Appendix 3:\n",
    "    T is a 3 x 2 matrix of p(Ht | Ht x Ht) entries -\n",
    "    probability of a truly H child from a mating where parents are truly H\n",
    "    \"\"\"\n",
    "    return jnp.array([\n",
    "        # R           L\n",
    "        [0.5 + ρ + α, 1 - (0.5 + ρ + α)],  # RxR\n",
    "        [0.5 + ρ + β, 1 - (0.5 + ρ + β)],  # RxL\n",
    "        [0.5 + ρ - α, 1 - (0.5 + ρ - α)]  # LxL\n",
    "    ])\n",
    "\n",
    "\n",
    "@jax.jit   \n",
    "def compute_P_gt(mp,t):\n",
    "    u = (mp - t) / mp  # The proportion of individuals measured as left handers that are truly right handers\n",
    "\n",
    "    # The matrix P is given by:\n",
    "    P = jnp.array([\n",
    "        [1, 0, 0],\n",
    "        [u, 1 - u, 0],\n",
    "        [u * u, 2 * u * (1 - u), (1 - u) * (1 - u)]\n",
    "    ])\n",
    "    return P\n",
    "\n",
    "\n",
    "@jax.jit   \n",
    "def compute_P_le(mp, t):\n",
    "    v = (t - mp) / (1 - mp)  # The proportion of individuals measured as right handed who are truly left handed\n",
    "    # The matrix P is given by:\n",
    "    P = jnp.array([\n",
    "        [(1 - v) * (1 - v), 2 * v * (1 - v), v * v],\n",
    "        [0, 1 - v, v],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    return P\n",
    "\n",
    "\n",
    "@jax.jit   \n",
    "def compute_P(mp, t):\n",
    "    \"\"\" Parents generation:\n",
    "    The matrix P gives the probability that a mating measured as RxR, RxL, or LxL is truly RxR, RxL, or LxL\"\"\"\n",
    "    return cond(mp > t, compute_P_gt, compute_P_le, mp, t)\n",
    "\n",
    "\n",
    "@jax.jit   \n",
    "def compute_O_gt(mo, t):\n",
    "    w = (mo - t) / (1 - t)  # The proportion of individuals measured as left handers that are truly right handers\n",
    "    # The matrix O is given by:\n",
    "    O = jnp.array([\n",
    "        [1 - w, w],\n",
    "        [0, 1]\n",
    "    ])\n",
    "    return O\n",
    "\n",
    "\n",
    "@jax.jit   \n",
    "def compute_O_le(mo, t):\n",
    "    x = 1 - (mo / t)  # The proportion of individuals measured as right handed who are truly left handed\n",
    "    # The matrix O is given by:\n",
    "    O = jnp.array([\n",
    "        [1, 0],\n",
    "        [x, 1 - x]\n",
    "    ])\n",
    "    return O\n",
    "    \n",
    "\n",
    "@jax.jit   \n",
    "def compute_O(mo, t):\n",
    "    \"\"\" Offspring generation:\n",
    "    The matrix O gives the probability of offspring measured as right or left handed given that it is truly right or left handed \"\"\"\n",
    "\n",
    "    return cond(mo > t, compute_O_gt, compute_O_le, mo, t)\n",
    "\n",
    "\n",
    "@jax.jit   \n",
    "def compute_M(T, P, O):\n",
    "    M = P @ T @ O\n",
    "    return M\n",
    "##################################################\n",
    "# Likelihood functions\n",
    "\n",
    "\n",
    "@jax.jit   \n",
    "def n_log_likelihood_St(θ, data):  # using the function Sm\n",
    "    # Check the length of θ to unpack the parameters accordingly\n",
    "    if len(θ) == 3:\n",
    "        ρ, α, β = θ\n",
    "    elif len(θ) == 2:\n",
    "        ρ, α = θ\n",
    "        β = 0  # Default value for β if not provided\n",
    "    else:\n",
    "        raise ValueError(\"Length of θ is {}\".format(len(θ)))  # Raise error if length of θ is not 2 or 3\n",
    "\n",
    "    # Validate the parameters θ\n",
    "    return -cond(\n",
    "        validate(θ), \n",
    "        log_likelihood_St_validated, \n",
    "        lambda ρ, α, β, data: -jnp.inf,  # Return infinity if θ is not valid\n",
    "        ρ, α, β, data\n",
    "    )\n",
    "\n",
    "\n",
    "@jax.jit   \n",
    "def log_likelihood_St_validated(ρ, α, β, data):\n",
    "    St = 0.0  # Initialize log-likelihood sum\n",
    "\n",
    "    # Compute T and t using the provided functions and parameters\n",
    "    T = compute_T(ρ, α, β)\n",
    "    t = compute_t(ρ, α, β)\n",
    "\n",
    "    # Estimation using the matrix M:\n",
    "\n",
    "    # Loop through each dataset in Data\n",
    "    for index, dataset in enumerate(data):\n",
    "        # Sum up the log-likelihood for the current dataset\n",
    "        St += jnp.nansum(xlogy(dataset, T.flatten()))\n",
    "\n",
    "    return St  # Return the computed log-likelihood sum\n",
    "\n",
    "\n",
    "\n",
    "@jax.jit   \n",
    "def n_log_likelihood_Sm(θ, data, mo, mp):  # using the function Sm\n",
    "\n",
    "    # Check the length of θ to unpack the parameters accordingly\n",
    "    if len(θ) == 3:\n",
    "        ρ, α, β = θ\n",
    "    elif len(θ) == 2:\n",
    "        ρ, α = θ\n",
    "        β = 0  # Default value for β if not provided\n",
    "    else:\n",
    "        raise ValueError(\"Length of θ is {}\".format(len(θ)))  # Raise error if length of θ is not 2 or 3\n",
    "\n",
    "    # Validate the parameters θ\n",
    "    return -cond(\n",
    "        validate(θ), \n",
    "        log_likelihood_Sm_validated, \n",
    "        lambda ρ, α, β, data, mo, mp: -jnp.inf,  # Return infinity if θ is not valid\n",
    "        ρ, α, β, data, mo, mp\n",
    "    )\n",
    "\n",
    "\n",
    "@jax.jit   \n",
    "def log_likelihood_Sm_validated(ρ, α, β, data, mo, mp):\n",
    "    Sm = 0.0  # Initialize log-likelihood sum\n",
    "\n",
    "    # Compute T and t using the provided functions and parameters\n",
    "    T = compute_T(ρ, α, β)\n",
    "    t = compute_t(ρ, α, β)\n",
    "\n",
    "    # Estimation using the matrix M:\n",
    "\n",
    "    # Loop through each dataset in Data\n",
    "    for index, dataset in enumerate(data):\n",
    "        # jax.debug.print(\"Sm={Sm}\", Sm=Sm)\n",
    "        # Retrieve mp and mo indices for the current dataset\n",
    "\n",
    "        mp_idx = mp[index]\n",
    "        mo_idx = mo[index]\n",
    "\n",
    "\n",
    "        # Compute P and O using the provided functions and mp, mo indices\n",
    "        P = compute_P(mp_idx, t)\n",
    "\n",
    "        O = compute_O(mo_idx, t)\n",
    "\n",
    "        # Compute matrix M using T, P, and O\n",
    "        M = compute_M(T, P, O)\n",
    "\n",
    "        # Sum up the log-likelihood for the current dataset\n",
    "        Sm += jnp.nansum(xlogy(dataset, M.flatten()))\n",
    "\n",
    "    return Sm  # Return the computed log-likelihood sum\n",
    "\n",
    "\n",
    "def fit(n_parameters, data, adjust, mo=None, mp=None):\n",
    "    \"\"\"\n",
    "    Fit the model parameters to the given data.\n",
    "\n",
    "    Parameters:\n",
    "    n_parameters (int): The number of parameters to estimate.\n",
    "    data (list or numpy.ndarray): The dataset to fit the model to.\n",
    "    adjust (bool): If True, use the Sm function; if False, use the St function.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Estimated parameters (θ_hat) and the maximum log-likelihood (logL).\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if adjust:\n",
    "        # Minimize negative log-likelihood using the Sm function\n",
    "        result  = sorted([opt.minimize(lambda x: n_log_likelihood_Sm(x, data, mo, mp), x0=[0.1, 0.1, 0.1][:n_parameters], method=\"Nelder-Mead\"), \n",
    "                          opt.minimize(lambda x: n_log_likelihood_Sm(x, data, mo, mp), x0=[0.01, 0.1, 0.1][:n_parameters], method=\"Nelder-Mead\"),\n",
    "                          opt.minimize(lambda x: n_log_likelihood_Sm(x, data, mo, mp), x0=[0.1, 0.01, 0.1][:n_parameters], method=\"Nelder-Mead\"),\n",
    "                          opt.minimize(lambda x: n_log_likelihood_Sm(x, data, mo, mp), x0=[0.45, 0.01, 0][:n_parameters], method=\"Nelder-Mead\"),\n",
    "                          opt.minimize(lambda x: n_log_likelihood_Sm(x, data, mo, mp), x0=[0.01, 0.45, 0][:n_parameters], method=\"Nelder-Mead\")], key=lambda x: x.fun)[0]\n",
    "\n",
    "                              \n",
    "                          \n",
    "        \n",
    "    else:\n",
    "        # Minimize negative log-likelihood using the St function\n",
    "        result  = sorted([opt.minimize(lambda x: n_log_likelihood_St(x, data), x0=[0.1, 0.1, 0.1][:n_parameters], method=\"Nelder-Mead\"), \n",
    "                          opt.minimize(lambda x: n_log_likelihood_St(x, data), x0=[0, 0.1, 0.1][:n_parameters], method=\"Nelder-Mead\"),\n",
    "                          opt.minimize(lambda x: n_log_likelihood_St(x, data), x0=[0.1, 0, 0.1][:n_parameters], method=\"Nelder-Mead\"),\n",
    "                          opt.minimize(lambda x: n_log_likelihood_St(x, data), x0=[0.45, 0.01, 0][:n_parameters], method=\"Nelder-Mead\"),\n",
    "                          opt.minimize(lambda x: n_log_likelihood_St(x, data), x0=[0.01, 0.45, 0][:n_parameters], method=\"Nelder-Mead\")], key=lambda x: x.fun)[0]\n",
    "\n",
    "    \n",
    "    return result.x\n",
    "\n",
    "def family_probs(ρ, α, β, size):\n",
    "    probs = []\n",
    "    T = compute_T(ρ, α, β)\n",
    "\n",
    "    for mating in range(3):\n",
    "        pr = T[mating][0]\n",
    "        p = [(comb(size, i) * pr ** (size-i) * (1-pr) ** i) for i in range(size+1)]\n",
    "        probs.append(p)\n",
    "    return np.array(probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fam_population(ρ, α, β, t, size):\n",
    "    \"\"\"\n",
    "    Create population (for 1 datset) of families given the model paramethers\n",
    "    :param ρ: Allele D effect.\n",
    "    :type ρ: float.\n",
    "    :param α: RxR parents effect.\n",
    "    :type α: float.\n",
    "    :param t: left-handedness rate.\n",
    "    :param size: The number of families in the dataset.\n",
    "    :type size: int.\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate the rate of allele C in population\n",
    "\n",
    "    population = []\n",
    "    parents = binom.rvs(p=t, n=2, size=size)\n",
    "\n",
    "    ### For each family generate children ###\n",
    "\n",
    "    for i in range(size):\n",
    "        fam_size = binom.rvs(p=0.354, n=4) + 1\n",
    "        p_type = parents[i]\n",
    "        prob = family_probs(ρ, α, β, fam_size)[p_type]\n",
    "        l = np.random.choice(range(1 + fam_size), p=prob)\n",
    "        population.append(np.array([p_type, fam_size, l]))\n",
    "\n",
    "    return np.array(population)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def true_to_measured_fam(population, t):\n",
    "    \"\"\"\n",
    "    Add to population (for 1 datset) bias to simulate criterion shift\n",
    "\n",
    "    :param population: The population we want to add bias to.\n",
    "    :type t: array.\n",
    "    :param t: p(L_t) - The true incidence of left-handedness.\n",
    "    :type t: float\n",
    "    \"\"\"\n",
    "\n",
    "    # Using laland(1995) observed rate of left handedness, and the model (t=0.1174) create bank of observed rates for the new pl\n",
    "    measured = t * np.array([0.1556, 0.0803, 0.0477, 0.0356, 0.0877, 0.0524, 0.2363, 0.1553, 0.1063, 0.0405,\n",
    "                              0.0976, 0.0987, 0.0831, 0.093, 0.1407, 0.1040, 0.0850, 0.0547, 0.13, 0.0756, 0.1842,\n",
    "                              0.0839, 0.2415, 0.1818, 0.1518, 0.1005, 0.134, 0.101, 0.0893, 0.0609, 0.091, 0.047,\n",
    "                              0.1071, 0.0952,\n",
    "                              0.19, 0.1885, 0.1188, 0.1845, 0.1283, 0.2424, 0.1332, 0.1711, 0.1411, 0.1667, 0.1512,\n",
    "                              0.1138, 0.1064,\n",
    "                              0.11, 0.1714, 0.1541, 0.1628, 0.1161, 0.197, 0.109, 0.1932, 0.1111, 0.1596,\n",
    "                              0.1477]) / 0.1174\n",
    "\n",
    "    # Choose observed rate for the parents and for offspring\n",
    "    parent, offspring = np.random.choice(measured, size=2, replace=True)\n",
    "\n",
    "    parent = min(1, parent)\n",
    "    offspring = min(1, offspring)\n",
    "\n",
    "    # Calculate p(Rm|Lt) and p(Lm|Rt) using the rates chosen and pl\n",
    "    if parent > t:\n",
    "        pRL_parent = 0\n",
    "        pLR_parent = (parent - t) / (1 - t)\n",
    "    else:\n",
    "        pRL_parent = 1 - (parent / t)\n",
    "        pLR_parent = 0\n",
    "\n",
    "    if offspring > t:\n",
    "        pRL_offspring = 0\n",
    "        pLR_offspring = (offspring - t) / (1 - t)\n",
    "    else:\n",
    "        pRL_offspring = 1 - (offspring / t)\n",
    "        pLR_offspring = 0\n",
    "\n",
    "    # Shift the population using calculated probabilities\n",
    "    for i in range(len(population)):\n",
    "\n",
    "        parents, children, lefts = population[i]\n",
    "\n",
    "        if parents == 0:\n",
    "            new_parents = int((np.random.random() < pLR_parent)) + int((np.random.random() < pLR_parent))\n",
    "\n",
    "        elif parents == 1:\n",
    "            new_parents = int((np.random.random() < pLR_parent)) + int((np.random.random() < (1 - pRL_parent)))\n",
    "\n",
    "        else:\n",
    "            new_parents = int((np.random.random() < (1 - pRL_parent))) + int((np.random.random() < (1 - pRL_parent)))\n",
    "\n",
    "        new_child = binom.rvs(p=(1 - pRL_offspring), n=lefts) + binom.rvs(p=pLR_offspring, n=(children - lefts))\n",
    "\n",
    "        population[i, 0] = new_parents\n",
    "        population[i, 2] = new_child\n",
    "\n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fam_pop_to_datasets(populations):\n",
    "    \"\"\"\n",
    "    Convert the populations to family datasets\n",
    "\n",
    "    :param population: populations of families.\n",
    "    :type population: list.\n",
    "    \"\"\"\n",
    "\n",
    "    data = []\n",
    "    measured = []\n",
    "\n",
    "    for population in populations:\n",
    "\n",
    "        # calculate the measured rates of left-handedness\n",
    "\n",
    "        measured.append(np.array(\n",
    "            [np.sum(population[:, 2]) / np.sum(population[:, 1]), np.sum(population[:, 0]) / (2 * len(population))]))\n",
    "\n",
    "        # Convert to triplets\n",
    "    \n",
    "        ds = np.zeros(6)\n",
    "        for family in population:\n",
    "            couple_type, fam_size, left_children = family\n",
    "            ds[2 * couple_type] += fam_size - left_children\n",
    "            ds[2 * couple_type + 1] += left_children\n",
    "        data.append(ds)\n",
    "    return np.array(data).reshape(-1, np.array(data).shape[-1]), np.array(measured)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fam_pop_to_multi_datasets(populations):\n",
    "    \"\"\"\n",
    "    Convert the populations to family datasets\n",
    "\n",
    "    :param population: populations of families.\n",
    "    :type population: list.\n",
    "    \"\"\"\n",
    "\n",
    "    data = []\n",
    "    measured = []\n",
    "\n",
    "    for population in populations:\n",
    "\n",
    "        # calculate the measured rates of left-handedness\n",
    "\n",
    "        measured.append(np.array(\n",
    "            [np.sum(population[:, 2]) / np.sum(population[:, 1]), np.sum(population[:, 0]) / (2 * len(population))]))\n",
    "\n",
    "        # Convert to triplets\n",
    "    \n",
    "        \n",
    "        ds = np.zeros((5, 18))\n",
    "        for family in population:\n",
    "            couple_type, fam_size, left_children = family\n",
    "            ds[fam_size - 1, 6 * couple_type + left_children] += 1\n",
    "\n",
    "        for size in range(5):\n",
    "            for cnt in range(size + 2, 6):\n",
    "                ds[size, cnt] = np.nan\n",
    "                ds[size, 6 + cnt] = np.nan\n",
    "                ds[size, 12 + cnt] = np.nan\n",
    "        data.append(ds)\n",
    "    return np.array(data).reshape(-1, np.array(data).shape[-1]), np.array(measured)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_datasets_to_fam_pop(datasets):\n",
    "    \"\"\"\n",
    "    Convert from multi table to populations\n",
    "\n",
    "    :param datasets: datasets of families.\n",
    "    :type datasets: list.\n",
    "    \"\"\"\n",
    "\n",
    "    populations = []\n",
    "    total_fams = 0\n",
    "    total_offspring = 0\n",
    "    l_total_parents = 0\n",
    "    l_total_offspring = 0\n",
    "\n",
    "    for i in range(len(datasets)//5):\n",
    "        population = []\n",
    "        ds = datasets[i*5:(i+1)*5]\n",
    "        for size in range(5):\n",
    "            for l in range(6):\n",
    "                population += [[0, size+1, l] for _ in range(int(np.nansum(ds[size, l])))]\n",
    "                population += [[1, size+1, l] for _ in range(int(np.nansum(ds[size, 6+l])))]\n",
    "                population += [[2, size+1, l] for _ in range(int(np.nansum(ds[size, 12+l])))]\n",
    "        population = np.array(population)\n",
    "        populations.append(population)\n",
    "\n",
    "        l_total_parents = np.sum(population[:,0])\n",
    "        total_fams = len(population)\n",
    "\n",
    "        l_total_offspring = np.sum(population[:,2])\n",
    "        total_offspring = np.sum(population[:,1])\n",
    "    \n",
    "    return populations, 0.5*l_total_parents/total_fams, l_total_offspring/total_offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(data):\n",
    "    \"\"\"\n",
    "    Bootstrap data\n",
    "    \"\"\"\n",
    "\n",
    "    new_data = []\n",
    "\n",
    "    for ds in data:\n",
    "        size = len(ds)\n",
    "        idxes = np.random.choice(range(size), size=size, replace=True)\n",
    "        new_ds = ds[idxes]\n",
    "        new_data.append(new_ds)\n",
    "\n",
    "\n",
    "    return fam_pop_to_datasets(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datasets(ρ, α, β, t, par, adjust=False):\n",
    "    np.random.seed()\n",
    "    if (par % 100 == 0):\n",
    "        print(f\"  {par}  \")\n",
    "    os.makedirs(f\"data/{adjust}\", exist_ok=True)\n",
    "\n",
    "    # Create triplets table:\n",
    "    if adjust:\n",
    "        triplets_data = [true_to_measured_fam(create_fam_population(ρ, α, β, t, np.random.randint(100, 2200)), t) for _\n",
    "                         in range(17)]\n",
    "    else:\n",
    "        triplets_data = [create_fam_population(ρ, α, β, t, np.random.randint(100, 2200)) for _ in range(17)]\n",
    "    multi, multi_measured = fam_pop_to_multi_datasets(triplets_data)\n",
    "    np.savetxt(f\"data/{adjust}/{ρ}_{α}.txt\", multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datasets_wrapper(n, adjust):\n",
    "    '''Shell function to generate datasets in parallel\n",
    "    :param n: number of datasets to generate\n",
    "    :type n: int\n",
    "    :param adjust: whether to adjust the datasets with criterion shift\n",
    "    :type adjust: bool\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    futures = []\n",
    "    f = generate_datasets\n",
    "    cpus = multiprocessing.cpu_count()\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=cpus) as executor:\n",
    "        ρ = np.random.random() * 0.5\n",
    "        α = np.random.random() * (0.5 - ρ)\n",
    "        kwargs = dict(ρ=ρ, α=α, β=0, t=compute_t(ρ,α,0), adjust=adjust)\n",
    "        fut = executor.submit(f, **kwargs)\n",
    "        futures.append(fut)\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        future.result()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the accuracy for  ρ = 0.277, α = 0.138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_2p(par, adjust_datasets =True, adjust_estimation = False):\n",
    "    np.random.seed()\n",
    "    if (par + 1) % 100 == 0:\n",
    "        print(f\"{par}\\n\")\n",
    "    ρ, α, β = 0.277, 0.138, 0\n",
    "    t = compute_t(ρ, α, β)\n",
    "    if adjust_datasets:\n",
    "        triplets_data = [true_to_measured_fam(create_fam_population(ρ, α, β, t, np.random.randint(100, 1200)),t) for _ in range(13)]\n",
    "    else:\n",
    "        triplets_data = [create_fam_population(ρ, α, β, t, np.random.randint(100, 1200)) for _ in range(13)]\n",
    "    triplets, triplets_measured = fam_pop_to_datasets(triplets_data)\n",
    "    return fit(2, triplets, adjust_estimation, triplets_measured[:,0].reshape(-1), triplets_measured[:,1].reshape(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sim_distribution(returns=1500, method=\"B\"):\n",
    "    α = []\n",
    "    ρ = []\n",
    "\n",
    "    futures = []\n",
    "    f = simulate_2p\n",
    "    \n",
    "    cpus = multiprocessing.cpu_count() - 2\n",
    "    adjust_datasets, adjust_estimation = {\"A\": (False, False), \n",
    "                                          \"B\": (True, False),\n",
    "                                          \"C\": (True, True)}[method]\n",
    "    with ProcessPoolExecutor(cpus) as executor:\n",
    "        for s_ in range(returns):\n",
    "            kwargs = dict(par=s_, adjust_datasets=adjust_datasets, adjust_estimation=adjust_estimation)\n",
    "            fut = executor.submit(f, **kwargs)\n",
    "            futures.append(fut)\n",
    "\n",
    "    for i, future in enumerate(as_completed(futures)):\n",
    "        r1, r2 = future.result()\n",
    "        ρ.append(r1)\n",
    "        α.append(r2)\n",
    "    print(\"finished\")\n",
    "    np.savetxt(f\"{method}_α.txt\", np.array(α))\n",
    "    np.savetxt(f\"{method}_ρ.txt\", np.array(ρ))\n",
    "    return np.array(ρ), np.array(α)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ρ,α = sim_distribution(15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ρ = np.loadtxt(\"B_ρ.txt\")\n",
    "α =  np.loadtxt(\"B_α.txt\")\n",
    "fig, axs = plt.subplots(2,1,figsize=(5,7))\n",
    "fontx = fonty = 12\n",
    "\n",
    "ax1 = axs[0]\n",
    "sns.histplot(α, ax= ax1, color=\"salmon\", bins=20, stat = \"probability\", label = \"α\")\n",
    "ax1.axvline(0.138, color = \"black\")\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2 = axs[1]\n",
    "sns.histplot(ρ, ax = ax2, color=\"teal\", bins = 20, stat = \"probability\", label = \"ρ\")\n",
    "ax2.axvline(0.277, color = \"black\")\n",
    "ax2.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is it happening for every ρ and α?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_datasets_wrapper(15000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noramalize_datasets(datasets):\n",
    "    new_datasets= []\n",
    "    for dataset in datasets:\n",
    "        new_dataset = dataset.copy()\n",
    "        for i in range(3):\n",
    "            sum = dataset[2*i] + dataset[2*i+1]\n",
    "            if sum == 0 :\n",
    "                new_dataset[2*i] = new_dataset[2*i +1] = 0.5\n",
    "            else:\n",
    "                new_dataset[2*i] = dataset[2*i]/sum\n",
    "                new_dataset[2*i+1] = dataset[2*i+1]/sum\n",
    "        new_datasets.append(new_dataset)\n",
    "    return np.array(new_datasets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_coverage(path, adjust, correction= [np.eye(2), 0]):\n",
    "    '''Calculate the coverage of the model\n",
    "    :param path: path to the datasets\n",
    "    :type path: str\n",
    "    :param adjust: whether to adjust the estimation with criterion shift\n",
    "    :type adjust: bool\n",
    "    '''\n",
    "    \n",
    "    data, l_parents, l_off = multi_datasets_to_fam_pop(np.loadtxt(path))\n",
    "    triplets, triplets_measured = fam_pop_to_datasets(data)\n",
    "    normalized_offspring_rates = noramalize_datasets([np.sum(triplets, axis=0)])\n",
    "    RRR_RLL_diff = normalized_offspring_rates[0,0] - normalized_offspring_rates[0,4]\n",
    "    np.random.seed()\n",
    "    mat, bias = correction\n",
    "    correction = lambda x: x@mat.T  + bias\n",
    "\n",
    "    path = path.replace(\"\\\\\", \"/\")\n",
    "    ρ , α = np.array(path.split(\"/\")[-1].replace(\".txt\",\"\").split(\"_\"), dtype=float)\n",
    "\n",
    "    # calculate condition number\n",
    "    NLL = lambda θ: n_log_likelihood_Sm(θ, triplets, triplets_measured[:, 0].reshape(-1), triplets_measured[:, 1].reshape(-1)) if adjust else n_log_likelihood_St(θ, triplets)\n",
    "    NLL_hess = jax.hessian(NLL)\n",
    "   \n",
    "    fim_true = NLL_hess(np.array([ρ, α]))\n",
    "    \n",
    "    # eigvals_true, eigvecs = jnp.linalg.eig(fim_true)\n",
    "    cn_true = jnp.linalg.cond(fim_true)\n",
    "    \n",
    "    # run MLE\n",
    "    ρ_MLE, α_MLE =  correction(fit(2, triplets, adjust, triplets_measured[:,0].reshape(-1), triplets_measured[:,1].reshape(-1)))\n",
    "    fim_mle = NLL_hess(np.array([ρ_MLE, α_MLE]))\n",
    "   \n",
    "    # eigvals_est, eigvecs = jnp.linalg.eig(fim_true)\n",
    "    cn_mle =jnp.linalg.cond(fim_mle)\n",
    "    \n",
    "    # save true and estimated params:\n",
    "    diff_ρ = [ρ, ρ_MLE]\n",
    "    diff_α = [α, α_MLE]\n",
    "\n",
    "    conf_ρ = np.zeros(100)\n",
    "    conf_α = np.zeros(100)\n",
    "    ρ_width = np.zeros(100)\n",
    "    α_width = np.zeros(100)\n",
    "\n",
    "    runs = 200\n",
    "    R = np.zeros(runs)\n",
    "    A = np.zeros(runs)\n",
    "    if np.random.random() < 1e-3:\n",
    "        print(ρ)\n",
    "    \n",
    "    for i in range(runs):\n",
    "        \n",
    "        triplets_bs, triplets_measured_bs = resample(data)\n",
    "        ρ_bs, α_bs = correction(fit(2, triplets_bs, adjust, triplets_measured_bs[:,0].reshape(-1), triplets_measured_bs[:,1].reshape(-1)))\n",
    "\n",
    "        R[i] = ρ_bs\n",
    "        A[i] = α_bs\n",
    "\n",
    "    # Check if the estimated parameters contained in intervals of alpha = (1,100)\n",
    "    R.sort()\n",
    "    A.sort()\n",
    "\n",
    "    \n",
    "\n",
    "    for alpha in np.arange(100):\n",
    "        conf = 1 - alpha / 100\n",
    "        upper_idx = int(runs * ((1 + conf) / 2) - 1)\n",
    "        lower_idx = int(runs * ((1 - conf) / 2))\n",
    "\n",
    "        if A[lower_idx] <= α <= A[upper_idx]:\n",
    "            conf_α[alpha] += 1\n",
    "\n",
    "        if R[lower_idx] <= ρ <= R[upper_idx]:\n",
    "            conf_ρ[alpha] += 1\n",
    "\n",
    "    return conf_α, conf_ρ, diff_α, diff_ρ, cn_true, cn_mle, l_parents, l_off, RRR_RLL_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage(path_to_folder, method=\"B\", correction = None):\n",
    "    \"\"\"\n",
    "    Shell function for runing coverage calculation in parllel\n",
    "    :param path_to_folder: path to the directory containing the datasets\n",
    "    :type path_to_folder: str\n",
    "    :param method: method to use for estimation {A, B, C}\n",
    "    :type method: str\n",
    "    :param correction: correction matrix and bias\n",
    "    :type correction: tuple\n",
    "    \n",
    "    :param returns: The fnumber of simulations used to calculate coverage.\n",
    "    :type returns: int.\n",
    "    \"\"\"\n",
    "\n",
    "    adjust = {\"A\": False, \"B\": False, \"C\": True}[method]\n",
    "    diff_α = []\n",
    "    diff_ρ = []\n",
    "    cn_est = []\n",
    "    cn_true = []\n",
    "    l_rate_p = []\n",
    "    l_rate_off =[]\n",
    "    conf_α = []\n",
    "    conf_ρ = []\n",
    "    α_width = []\n",
    "    ρ_width = []\n",
    "    rates_diff = []\n",
    "    if correction == None:\n",
    "        correction =([np.eye(2), 0])\n",
    "    simulations = len(os.listdir(path_to_folder))\n",
    "\n",
    "    futures = []\n",
    "    f = calc_coverage\n",
    "\n",
    "    cpus = multiprocessing.cpu_count() -5\n",
    "\n",
    "    with ProcessPoolExecutor(cpus) as executor:\n",
    "         for filename in sorted(os.listdir(path_to_folder)):\n",
    "            file_path = os.path.join(path_to_folder, filename)\n",
    "            kwargs = dict(path=file_path, adjust=adjust, correction=correction)\n",
    "            fut = executor.submit(f, **kwargs)\n",
    "            futures.append(fut)\n",
    "           \n",
    "    for future in as_completed(futures):\n",
    "        α, ρ, α_diff, ρ_diff, cn_t, cn_e, l_parents, l_off, RRR_RLL_diff = future.result()\n",
    "        conf_α.append(α)\n",
    "        conf_ρ.append(ρ)\n",
    "        diff_α.append(α_diff)\n",
    "        diff_ρ.append(ρ_diff)\n",
    "        cn_true.append(cn_t)\n",
    "        cn_est.append(cn_e)\n",
    "        l_rate_p.append(l_parents)\n",
    "        l_rate_off.append(l_off)\n",
    "        rates_diff.append(RRR_RLL_diff)\n",
    "        \n",
    "        \n",
    "        \n",
    "    conf_α = np.array(conf_α)\n",
    "    conf_ρ = np.array(conf_ρ)\n",
    "    diff_α = np.array(diff_α)\n",
    "    diff_ρ = np.array(diff_ρ)\n",
    "    cn_true = np.array(cn_true)\n",
    "    cn_est = np.array(cn_est)\n",
    "    l_rate_p = np.array(l_rate_p)\n",
    "    l_rate_off = np.array(l_rate_off)\n",
    "    rates_diff = np.array(rates_diff)\n",
    "    \n",
    "    \n",
    "    \n",
    "    data = {\n",
    "        \"true_α\": diff_α[:, 0],\n",
    "        \"true_ρ\": diff_ρ[:, 0],\n",
    "        \"left_parents\" : l_rate_p,\n",
    "        \"left_offsprings\" : l_rate_off,\n",
    "        \"R|RR - R|LL\": rates_diff,\n",
    "        \"est_α\": diff_α[:, 1],\n",
    "        \"est_ρ\": diff_ρ[:, 1],\n",
    "        \"cn_true\": cn_true,\n",
    "        \"cn_mle\": cn_est,\n",
    "        **{f\"conf_α_{i}\": conf_α[:, i] for i in range(conf_α.shape[1])},\n",
    "        **{f\"conf_ρ_{i}\": conf_ρ[:, i] for i in range(conf_ρ.shape[1])},\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data) \n",
    "\n",
    "    df.to_csv(f\"{method}_{'' if correction == None else 'corrected_'}coverage.csv\")\n",
    "\n",
    "    return conf_α, conf_ρ, diff_α, diff_ρ, cn_true,cn_e,l_rate_p,l_rate_off,rates_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage(\"data/True\", \"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(dataset_path, value_range):\n",
    "    data = pd.read_csv(dataset_path, index_col=0)\n",
    "    filtered_data = data[(data[\"left_parents\"] >= value_range[0]) & (data[\"left_parents\"] <= value_range[1]) & (data[\"left_offsprings\"]\t>= value_range[0]) & (data[\"left_offsprings\"] <= value_range[1])]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "    # α\n",
    "    true_α = filtered_data[\"true_α\"]\n",
    "    true_ρ = filtered_data[\"true_ρ\"]\n",
    "    est_α = filtered_data[\"est_α\"]\n",
    "    est_ρ = filtered_data[\"est_ρ\"]\n",
    "    cn = filtered_data[\"cn_true\"]\n",
    "\n",
    "    scatter_a = axes[0, 0].scatter(true_α, est_α, c=np.log10(cn), s=1)\n",
    "    axes[0, 0].plot([0,0.5],[0,0.5], color='black', linestyle='--')\n",
    "    axes[0, 0].set_title(\"α\")\n",
    "    axes[0, 0].set_xlabel(\"True α\")\n",
    "    axes[0, 0].set_ylabel(\"Estimated α\")\n",
    "    axes[0, 0].set_xlim(0, 0.5)\n",
    "    axes[0, 0].set_ylim(0, 0.5)\n",
    "\n",
    "    cbar = fig.colorbar(scatter_a, ax=axes[0, 0])\n",
    "\n",
    "    coverage_α = np.array([np.sum(filtered_data[f\"conf_α_{i}\"].values) for i in range(100)])/len(filtered_data)\n",
    "    coverage_ρ = np.array([np.sum(filtered_data[f\"conf_ρ_{i}\"].values) for i in range(100)])/len(filtered_data)\n",
    "\n",
    "    axes[1, 0].plot(np.arange(0,100), coverage_α[::-1], color='teal')\n",
    "    axes[1, 0].plot([0,100], [0,1], color='black', linestyle='--')\n",
    "    axes[1, 0].set_xlabel(\"Confidence level\")\n",
    "    axes[1, 0].set_ylabel(\"Coverage\")\n",
    "    axes[1, 0].set_ylim(0,1)\n",
    "    axes[1, 0].set_xlim(0,100)\n",
    "\n",
    "    # ρ\n",
    "    scatter_r = axes[0, 1].scatter(true_ρ, est_ρ, c=np.log10(cn), s=1)\n",
    "    axes[0, 1].plot([0, 0.5], [0, 0.5], color='black', linestyle='--')\n",
    "    axes[0, 1].set_title(\"ρ\")\n",
    "    axes[0, 1].set_xlabel(\"True ρ\")\n",
    "    axes[0, 1].set_ylabel(\"Estimated ρ\")\n",
    "    cbar = fig.colorbar(scatter_r, ax=axes[0, 1])\n",
    "    axes[0, 1].set_xlim(0, 0.5)\n",
    "    axes[0, 1].set_ylim(0, 0.5)\n",
    "\n",
    "    axes[1,1].plot(np.arange(0,100), coverage_ρ[::-1], color='salmon')\n",
    "    axes[1,1].plot([0,100], [0,1], color='black', linestyle='--')\n",
    "    axes[1,1].set_xlabel(\"Confidence level\")\n",
    "    axes[1,1].set_ylabel(\"Coverage\")\n",
    "    axes[1,1].set_ylim(0,1)\n",
    "    axes[1,1].set_xlim(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_slider = widgets.FloatRangeSlider(\n",
    "    value=[0.0, 100],\n",
    "    min=0,\n",
    "    max=1,\n",
    "    step=0.001,\n",
    "    description='left-rate %:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Link widgets to plot function\n",
    "interact(plot_graph, dataset_path=\"B_coverage.csv\", value_range=range_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can it be corrected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"B_coverage.csv\")\n",
    "true_α = data[\"true_α\"]\n",
    "true_ρ = data[\"true_ρ\"]\n",
    "est_α = data[\"est_α\"]\n",
    "est_ρ = data[\"est_ρ\"]\n",
    "\n",
    "\n",
    "\n",
    "est_params = np.array([est_α, est_ρ])\n",
    "\n",
    "model_α2 = LinearRegression()\n",
    "model_α2.fit(est_params.T, true_α)\n",
    "model_ρ2 = LinearRegression()\n",
    "model_ρ2.fit(est_params.T, true_ρ)\n",
    "α_pred2 = model_α2.predict(est_params.T)\n",
    "ρ_pred2 = model_ρ2.predict(est_params.T)\n",
    "r_squared_α2 = r2_score(true_α, α_pred2)\n",
    "r_squared_ρ2 = r2_score(true_ρ, ρ_pred2)\n",
    "\n",
    "model_α2.coef_ = model_α2.coef_\n",
    "model_α2.intercept_ = model_α2.intercept_\n",
    "model_ρ2.coef_ = model_ρ2.coef_\n",
    "model_ρ2.intercept_ = model_ρ2.intercept_\n",
    "\n",
    "mat = np.array([[model_ρ2.coef_[1], model_ρ2.coef_[0]], [model_α2.coef_[1], model_α2.coef_[0]]])\n",
    "bias = np.array([model_ρ2.intercept_, model_α2.intercept_])\n",
    "\n",
    "mat, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage(\"data/True\", \"B\", correction = [mat, bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
    "# plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "fontx = fonty = 12\n",
    "\n",
    "lower_bound = 0.05\n",
    "upper_bound = 0.6\n",
    "\n",
    "\n",
    "\n",
    "ρ = np.loadtxt(\"B_ρ.txt\")\n",
    "α =  np.loadtxt(\"B_α.txt\")\n",
    "x = np.array([ρ,α]).reshape(2,-1)\n",
    "corrected_ρ, corrected_α = ((mat @ x).T + bias).T\n",
    "\n",
    "\n",
    "ax11 = axs[0,0]\n",
    "sns.histplot(corrected_α, ax= ax11, color=\"salmon\", bins=20, stat = \"probability\", label = \"α\")\n",
    "ax11.axvline(0.138, color = \"black\")\n",
    "ax11.legend()\n",
    "\n",
    "\n",
    "ax12 = axs[1,0]\n",
    "sns.histplot(corrected_ρ, ax = ax12, color=\"teal\", bins = 20, stat = \"probability\", label = \"ρ\")\n",
    "ax12.axvline(0.277, color = \"black\")\n",
    "ax12.legend()\n",
    "ax12.set_xlabel(\"Estimated parameter value\", fontsize=fontx)\n",
    "\n",
    "\n",
    "B = pd.read_csv(\"B_corrected_coverage.csv\")\n",
    "\n",
    "\n",
    "diff_α = B[[\"true_α\",\"est_α\"]].values\n",
    "diff_ρ = B[[\"true_ρ\",\"est_ρ\"]].values\n",
    "\n",
    "ax21 = axs[0,1]\n",
    "ax22 = axs[1, 1]\n",
    "ax21.scatter(diff_α[:, 0], diff_α[:, 1], label=\"α\", s=1, color=\"salmon\")\n",
    "ax21.plot([0, np.max(diff_α)], [0, np.max(diff_α)], \"--\", color=\"black\")\n",
    "ax21.set_xlim(0, 0.5)\n",
    "ax21.set_ylim(0, 0.5)\n",
    "ax21.set_xlabel(\"true parameter\", fontsize=fontx)\n",
    "\n",
    "ax22.scatter(diff_ρ[:, 0], diff_ρ[:, 1],  label=\"ρ\", s=1, color=\"teal\")\n",
    "ax22.plot([0, np.max(diff_ρ)], [0, np.max(diff_ρ)], \"--\", color=\"black\")\n",
    "ax22.set_xlim(0, np.max(diff_ρ))\n",
    "ax22.set_xlabel(\"true parameter\", fontsize=fontx)\n",
    "ax22.set_ylabel('estimated parameter', fontsize=fonty)\n",
    "ax22.set_ylim(0, np.max(diff_ρ))\n",
    "\n",
    "\n",
    "ax31 = axs[0, 2]\n",
    "ax31.plot(np.arange(0,100), np.array([np.sum(B[f\"conf_α_{99-i}\"].values) for i in range(100)])/len(B), color='salmon')\n",
    "ax31.plot([0,100], [0,1], color='black', linestyle='--')\n",
    "ax31.set_xlabel(\"Confidence level\", fontsize=fontx)\n",
    "ax31.set_ylabel(\"Coverage\", fontsize=fonty)\n",
    "\n",
    "ax32 = axs[1, 2]\n",
    "ax32.plot(np.arange(0,100), np.array([np.sum(B[f\"conf_ρ_{99-i}\"].values) for i in range(100)])/len(B), color='teal')\n",
    "ax32.plot([0,100], [0,1], color='black', linestyle='--')\n",
    "ax32.set_xlabel(\"Confidence level\", fontsize=fontx)\n",
    "ax32.set_ylabel(\"Coverage\", fontsize=fonty)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about the other estimation methods (A,C)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### laland's parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ρ,α = sim_distribution(15000, \"A\")\n",
    "ρ,α = sim_distribution(15000, \"C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage(\"data/False\", \"A\")\n",
    "coverage(\"data/True\", \"C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"B_coverage.csv\")\n",
    "true_α = data[\"true_α\"]\n",
    "true_ρ = data[\"true_ρ\"]\n",
    "est_α = data[\"est_α\"]\n",
    "est_ρ = data[\"est_ρ\"]\n",
    "\n",
    "\n",
    "\n",
    "est_params = np.array([est_α, est_ρ])\n",
    "\n",
    "model_α2 = LinearRegression()\n",
    "model_α2.fit(est_params.T, true_α)\n",
    "model_ρ2 = LinearRegression()\n",
    "model_ρ2.fit(est_params.T, true_ρ)\n",
    "α_pred2 = model_α2.predict(est_params.T)\n",
    "ρ_pred2 = model_ρ2.predict(est_params.T)\n",
    "r_squared_α2 = r2_score(true_α, α_pred2)\n",
    "r_squared_ρ2 = r2_score(true_ρ, ρ_pred2)\n",
    "\n",
    "model_α2.coef_ = model_α2.coef_\n",
    "model_α2.intercept_ = model_α2.intercept_\n",
    "model_ρ2.coef_ = model_ρ2.coef_\n",
    "model_ρ2.intercept_ = model_ρ2.intercept_\n",
    "\n",
    "mat = np.array([[model_ρ2.coef_[1], model_ρ2.coef_[0]], [model_α2.coef_[1], model_α2.coef_[0]]])\n",
    "bias = np.array([model_ρ2.intercept_, model_α2.intercept_])\n",
    "ρ = np.loadtxt(\"B_ρ.txt\")\n",
    "α =  np.loadtxt(\"B_α.txt\")\n",
    "x = np.array([ρ,α]).reshape(2,-1)\n",
    "corrected_ρ, corrected_α = ((mat @ x).T + bias).T\n",
    "\n",
    "\n",
    "datasets = {\n",
    "    \"A\": [pd.read_csv(\"A_coverage.csv\", index_col=0), np.loadtxt(\"A_α.txt\"), np.loadtxt(\"A_ρ.txt\")],\n",
    "    \"B\": [pd.read_csv(\"B_coverage.csv\", index_col=0), np.loadtxt(\"B_α.txt\"), np.loadtxt(\"B_ρ.txt\")],\n",
    "    \"B with correction\": [pd.read_csv(\"B_corrected_coverage.csv\", index_col=0), corrected_α, corrected_ρ],\n",
    "    \"C\": [pd.read_csv(\"C_coverage.csv\", index_col=0), np.loadtxt(\"C_α.txt\"), np.loadtxt(\"C_ρ.txt\")],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to plot the graphs\n",
    "def plot_graph1(estemation_method=\"B\", l_rate=[0,1], min_diff = 0):\n",
    "    data, α, ρ = datasets[estemation_method]\n",
    "    min_rate, max_rate = l_rate\n",
    "    filtered_data = data[(data[\"left_parents\"] >= min_rate) & (data[\"left_offsprings\"]>= min_rate) & \n",
    "                         (data[\"left_parents\"] <= max_rate) & (data[\"left_offsprings\"] <= max_rate) &\n",
    "                         (np.abs(data[\"R|RR - R|LL\"]) >=min_diff)]\n",
    "    print(f\"Filtered {len(data) - len(filtered_data)} datasets\")\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    #lalands params\n",
    "    ax11 = axs[0,0]\n",
    "    sns.histplot(α, ax= ax11, color=\"salmon\", bins=50, stat = \"probability\", label = \"α\")\n",
    "    ax11.axvline(0.138,color = \"black\")\n",
    "    ax11.legend()\n",
    "\n",
    "\n",
    "    ax12 = axs[1,0]\n",
    "    sns.histplot(ρ, ax = ax12, color=\"teal\", bins = 50, stat = \"probability\", label = \"ρ\")\n",
    "    ax12.axvline(0.277, color = \"black\")\n",
    "    ax12.legend()\n",
    "    ax12.set_xlabel(\"Estimated parameter value\", fontsize=fontx)\n",
    "\n",
    "    # General params\n",
    "    diff_α = filtered_data[[\"true_α\",\"est_α\"]].values\n",
    "    diff_ρ = filtered_data[[\"true_ρ\",\"est_ρ\"]].values    \n",
    "    ax21 = axs[0,1]\n",
    "    ax22 = axs[1, 1]\n",
    "    ax21.scatter(diff_α[:, 0], diff_α[:, 1], label=\"α\", s=1, color=\"salmon\")\n",
    "    ax21.plot([0, 0.5], [0, 0.5], \"--\", color=\"black\")\n",
    "    ax21.set_xlim(0, 0.5)\n",
    "    ax21.set_ylim(0, 0.5)\n",
    "    ax21.set_xlabel(\"true parameter\", fontsize=fontx)\n",
    "\n",
    "    ax22.scatter(diff_ρ[:, 0], diff_ρ[:, 1],  label=\"ρ\", s=1, color=\"teal\")\n",
    "    ax22.plot([0, 0.5], [0, 0.5], \"--\", color=\"black\")\n",
    "    ax22.set_xlim(0, 0.5)\n",
    "    ax22.set_xlabel(\"true parameter\", fontsize=fontx)\n",
    "    ax22.set_ylabel('estimated parameter', fontsize=fonty)\n",
    "    ax22.set_ylim(0, 0.5)\n",
    "\n",
    "    # Coverage analysis\n",
    "    ax31 = axs[0, 2]\n",
    "    ax31.plot(np.arange(0,100), np.array([np.sum(filtered_data[f\"conf_α_{99-i}\"].values) for i in range(100)])/len(filtered_data), color='salmon', lw=3)\n",
    "    ax31.plot([0,100], [0,1], color='black', linestyle='--')\n",
    "    ax31.set_xlabel(\"Confidence level\", fontsize=fontx)\n",
    "    ax31.set_ylabel(\"Coverage\", fontsize=fonty)\n",
    "\n",
    "    ax32 = axs[1, 2]\n",
    "    ax32.plot(np.arange(0,100), np.array([np.sum(filtered_data[f\"conf_ρ_{99-i}\"].values) for i in range(100)])/len(filtered_data), color='teal', lw=3)\n",
    "    ax32.plot([0,100], [0,1], color='black', linestyle='--')\n",
    "    ax32.set_xlabel(\"Confidence level\", fontsize=fontx)\n",
    "    ax32.set_ylabel(\"Coverage\", fontsize=fonty)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    cn = filtered_data[\"cn_true\"].values\n",
    "    cn[~np.isfinite(cn)] =1e9\n",
    "    sns.kdeplot(np.log10(cn))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dropdown = widgets.Dropdown(\n",
    "    options=list(datasets.keys()),\n",
    "    value=\"B\",\n",
    "    description=\"method:\"\n",
    ")\n",
    "\n",
    "slider = widgets.FloatRangeSlider(\n",
    "    value=[0,1],\n",
    "    min=0,\n",
    "    max=1,\n",
    "    step=0.01,\n",
    "    description='left-rate %:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "slider2 = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=0.1,\n",
    "    step=0.01,\n",
    "    description='min |p(R|RR) - p(R|LL)|:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Link widgets to plot function\n",
    "interact(plot_graph1, estemation_method=dataset_dropdown, l_rate=slider, min_diff=slider2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
